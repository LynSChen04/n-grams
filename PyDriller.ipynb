{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hvX-82iaJjEf"
      },
      "outputs": [],
      "source": [
        "!pip install pydriller\n",
        "!pip install javalang"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s11PkawhYPLS"
      },
      "outputs": [],
      "source": [
        "#### GHS ####"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xPeaXxjOKqFs"
      },
      "outputs": [],
      "source": [
        "!add-apt-repository ppa:git-core/ppa\n",
        "!apt-get update\n",
        "!apt-get install git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JOyEEFLDLDBA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from pydriller import Repository\n",
        "import os\n",
        "from javalang.parse import parse\n",
        "from javalang.tree import MethodDeclaration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "ki3dBwJ3XqGf"
      },
      "outputs": [],
      "source": [
        "df_res = pd.read_csv('ghs-repos.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5dFLR9wCXxcF",
        "outputId": "a49e274b-2ced-41fc-ab64-27b3d4ecabd9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['https://www.github.com/dustin/java-memcached-client',\n",
              " 'https://www.github.com/davidb/scala-maven-plugin',\n",
              " 'https://www.github.com/tcurdt/jdeb',\n",
              " 'https://www.github.com/junit-team/junit4',\n",
              " 'https://www.github.com/yui/yuicompressor']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "repoList = []\n",
        "for idx,row in df_res.iterrows():\n",
        "  repoList.append(\"https://www.github.com/{}\".format(row['name']))\n",
        "repoList[0:5]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AdPhm715LucJ"
      },
      "source": [
        "#Importance of Collecting High-Quality Data from GitHub Repositories\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "High-quality data is the backbone of training effective and reliable machine learning models, especially for tasks involving code and natural language. GitHub repositories offer a vast amount of real-world, diverse data, making them an invaluable resource for building advanced models like LLMs for software engineering.\n",
        "However, not all repositories are equally relevant or well-maintained. Selecting only relevant repositories ensures that the da\n",
        "ta aligns with the task at hand, minimizing noise and improving the modelâ€™s performance. This approach also reduces the risk of introducing low-quality or misleading patterns into the training process, resulting in models that are both robust and practical. Thus, we need to collect source code using specific criteria. An helping hand is provided by the following platform:\n",
        "[GHS](https://seart-ghs.si.usi.ch/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0ys2hMonnA4"
      },
      "outputs": [],
      "source": [
        "from pydriller import Repository\n",
        "import os\n",
        "import csv\n",
        "from javalang.parse import parse\n",
        "from javalang.tree import MethodDeclaration\n",
        "import javalang\n",
        "\n",
        "def extract_methods_from_java(code):\n",
        "    \"\"\"\n",
        "    Extract methods from Java source code using javalang parser.\n",
        "\n",
        "    Args:\n",
        "        code (str): The Java source code.\n",
        "\n",
        "    Returns:\n",
        "        list: A list of tuples containing method names and their full source code.\n",
        "    \"\"\"\n",
        "    methods = []\n",
        "    try:\n",
        "        # Parse the code into an Abstract Syntax Tree (AST)\n",
        "        tree = javalang.parse.parse(code)\n",
        "        lines = code.splitlines()\n",
        "\n",
        "        # Traverse the tree to find method declarations\n",
        "        for _, node in tree.filter(javalang.tree.MethodDeclaration):\n",
        "            method_name = node.name\n",
        "\n",
        "            # Determine the start and end lines of the method\n",
        "            start_line = node.position.line - 1\n",
        "            end_line = None\n",
        "\n",
        "            # Use the body of the method to determine its end position\n",
        "            if node.body:\n",
        "                last_statement = node.body[-1]\n",
        "                if hasattr(last_statement, 'position') and last_statement.position:\n",
        "                    end_line = last_statement.position.line\n",
        "\n",
        "            # Extract method code\n",
        "            if end_line:\n",
        "                method_code = \"\\n\".join(lines[start_line:end_line+1])\n",
        "            else:\n",
        "                # If end_line couldn't be determined, extract up to the end of the file\n",
        "                method_code = \"\\n\".join(lines[start_line:])\n",
        "\n",
        "            methods.append((method_name, method_code))\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error parsing Java code: {e}\")\n",
        "    return methods\n",
        "\n",
        "\n",
        "def extract_methods_to_csv_from_master(repo_path, output_csv):\n",
        "    \"\"\"\n",
        "    Extract methods from Java files in the master branch and save them in a CSV file.\n",
        "\n",
        "    Args:\n",
        "        repo_path (str): Path to the Git repository.\n",
        "        output_csv (str): Path to the output CSV file.\n",
        "    \"\"\"\n",
        "    with open(output_csv, mode='w', newline='', encoding='utf-8') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        csv_writer.writerow([\"Commit Hash\", \"File Name\", \"Method Name\", \"Method Code\", \"Commit Link\"])\n",
        "\n",
        "        for commit in Repository(repo_path, only_in_branch=\"master\").traverse_commits():\n",
        "            print(f\"Processing commit: {commit.hash}\")\n",
        "\n",
        "            #We only look into the modified files. In other words, we are looking into the history of the software system by traversing each commit.\n",
        "            #Various Generative AI methods for SD have been trained on data collected in this way; for example bug fixing.\n",
        "            for modified_file in commit.modified_files:\n",
        "                if modified_file.filename.endswith(\".java\") and modified_file.source_code:\n",
        "                    methods = extract_methods_from_java(modified_file.source_code)\n",
        "\n",
        "                    for method_name, method_code in methods:\n",
        "                        commit_link = f\"{repo_path}/commit/{commit.hash}\"\n",
        "                        csv_writer.writerow([commit.hash, modified_file.filename, method_name, method_code, commit_link])\n",
        "\n",
        "                    print(f\"Extracted methods from {modified_file.filename} in commit {commit.hash}\")\n",
        "\n",
        "\n",
        "def extract_methods_to_csv(repo_path, output_csv):\n",
        "    \"\"\"\n",
        "    Extract methods from Java files in a repository and save them in a CSV file.\n",
        "\n",
        "    Args:\n",
        "        repo_path (str): Path to the Git repository.\n",
        "        output_csv (str): Path to the output CSV file.\n",
        "    \"\"\"\n",
        "    with open(output_csv, mode='w', newline='', encoding='utf-8') as csvfile:\n",
        "        csv_writer = csv.writer(csvfile)\n",
        "        csv_writer.writerow([\"Branch Name\", \"Commit Hash\", \"File Name\", \"Method Name\", \"Method Code\", \"Commit Link\"])\n",
        "\n",
        "        branch_name = \"master\"\n",
        "        for commit in Repository(repo_path, only_in_branch=branch_name).traverse_commits():\n",
        "            print(f\"Processing commit: {commit.hash}\")\n",
        "\n",
        "            for modified_file in commit.modified_files:\n",
        "                if modified_file.filename.endswith(\".java\") and modified_file.source_code:\n",
        "                    methods = extract_methods_from_java(modified_file.source_code)\n",
        "\n",
        "                    for method_name, method_code in methods:\n",
        "                        commit_link = f\"{repo_path}/commit/{commit.hash}\"\n",
        "                        csv_writer.writerow([branch_name, commit.hash, modified_file.filename, method_name, method_code, commit_link])\n",
        "\n",
        "                    print(f\"Extracted methods from {modified_file.filename} in commit {commit.hash}\")\n",
        "\n",
        "\n",
        "\n",
        "for repo in repoList[0:1]:\n",
        "\n",
        "    fileNameToSave = ''.join(repo.split('github.com')[1:])\n",
        "    fileNameToSave = fileNameToSave.replace('/','_')\n",
        "\n",
        "    # Specify the path to the output CSV file\n",
        "    output_csv_file = \"extracted_methods_{}.csv\".format(fileNameToSave)\n",
        "    # Run the extraction\n",
        "    extract_methods_to_csv_from_master(repo, output_csv_file)\n",
        "\n",
        "\n",
        "    print(repo)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IgXQGttaa5mM"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}